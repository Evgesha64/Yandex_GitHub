{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект: Обучение с учителем - качество модели\n",
    "\n",
    "## Описание проекта\n",
    "Интернет-магазин «В один клик» продаёт разные товары: для детей, для дома, мелкую бытовую технику, косметику и даже продукты. Отчёт магазина за прошлый период показал, что активность покупателей начала снижаться. \n",
    "\n",
    "**Цель проекта**: Разработать решение, которое позволит персонализировать предложения постоянным клиентам, чтобы увеличить их покупательскую активность.\n",
    "\n",
    "**Задача**: Построить модель, которая предскажет вероятность снижения покупательской активности клиента в следующие три месяца.\n",
    "\n",
    "## Описание данных\n",
    "В проекте используются следующие данные:\n",
    "- market_file.csv - основные данные о клиентах (1300 клиентов, 13 признаков)\n",
    "- market_money.csv - данные о выручке по периодам (3900 записей)\n",
    "- market_time.csv - данные о времени на сайте (2600 записей)\n",
    "- money.csv - данные о прибыльности клиентов (1300 записей)\n",
    "\n",
    "## Целевая переменная\n",
    "**Покупательская активность**:\n",
    "- \"Прежний уровень\" - 802 клиента (61.7%)\n",
    "- \"Снизилась\" - 498 клиентов (38.3%)\n",
    "\n",
    "## Методология\n",
    "1. **Загрузка и предобработка данных**\n",
    "2. **Исследовательский анализ данных (EDA)**\n",
    "3. **Объединение таблиц**\n",
    "4. **Корреляционный анализ**\n",
    "5. **Построение и обучение моделей**\n",
    "6. **Анализ важности признаков**\n",
    "7. **Сегментация покупателей**\n",
    "8. **Выводы и рекомендации**\n",
    "\n",
    "## Ожидаемые результаты\n",
    "- Модель машинного обучения для предсказания снижения активности клиентов\n",
    "- Анализ важности признаков для понимания факторов риска\n",
    "- Сегментация клиентов с персонализированными рекомендациями\n",
    "- Полный отчет с выводами и рекомендациями для бизнеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Научные вычисления\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Визуализация\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "\n",
    "# Стандартные библиотеки\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Научные вычисления\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Машинное обучение - общие\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    f1_score, \n",
    "    make_scorer, \n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    MinMaxScaler, \n",
    "    OneHotEncoder, \n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "# Машинное обучение - модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Настройка предупреждений и отображения\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Библиотеки успешно импортированы!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных с обработкой ошибок\n",
    "import os\n",
    "\n",
    "print(\"=== ЗАГРУЗКА ДАННЫХ ===\")\n",
    "print()\n",
    "\n",
    "# Функция для безопасной загрузки файла\n",
    "def load_csv_safe(filename, sep=','):\n",
    "    \"\"\"Безопасная загрузка CSV файла с проверкой существования путей\"\"\"\n",
    "    paths = [\n",
    "        f\"datasets/{filename}\",\n",
    "        f\"/datasets/{filename}\",\n",
    "        f\"https://code.s3.yandex.net/datasets/{filename}\"\n",
    "    ]\n",
    "    \n",
    "    for path in paths:\n",
    "        if path.startswith('http') or os.path.exists(path):\n",
    "            try:\n",
    "                data = pd.read_csv(path, sep=sep)\n",
    "                print(f\"✅ Данные {path} загружены успешно.\")\n",
    "                print(f\"   Размер: {data.shape}\")\n",
    "                return data\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Не удалось загрузить {path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    raise FileNotFoundError(f\"❌ Ошибка: Не удалось найти файл {filename} ни по одному из путей\")\n",
    "\n",
    "# Загрузка market_file.csv (основные данные о клиентах)\n",
    "market_file = load_csv_safe(\"market_file.csv\")\n",
    "\n",
    "# Загрузка market_money.csv (данные о выручке)\n",
    "market_money = load_csv_safe(\"market_money.csv\")\n",
    "\n",
    "# Загрузка market_time.csv (данные о времени на сайте)\n",
    "market_time = load_csv_safe(\"market_time.csv\")\n",
    "\n",
    "# Загрузка money.csv (данные о прибыли)\n",
    "money = load_csv_safe(\"money.csv\", sep=\";\")\n",
    "\n",
    "print()\n",
    "print(\"✅ Все файлы загружены успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 1.2: Первичная проверка данных\n",
    "Проверка размеров, типов данных и пропущенных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первичная проверка данных\n",
    "print(\"=== ПЕРВИЧНАЯ ПРОВЕРКА ДАННЫХ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Проверяем размеры данных\n",
    "print(\"1. РАЗМЕРЫ ДАННЫХ:\")\n",
    "print(f\"   market_file: {market_file.shape}\")\n",
    "print(f\"   market_money: {market_money.shape}\")\n",
    "print(f\"   market_time: {market_time.shape}\")\n",
    "print(f\"   money: {money.shape}\")\n",
    "print()\n",
    "\n",
    "# 2. Проверяем типы данных\n",
    "print(\"2. ТИПЫ ДАННЫХ:\")\n",
    "print(\"   market_file:\")\n",
    "print(market_file.dtypes)\n",
    "print()\n",
    "print(\"   market_money:\")\n",
    "print(market_money.dtypes)\n",
    "print()\n",
    "print(\"   market_time:\")\n",
    "print(market_time.dtypes)\n",
    "print()\n",
    "print(\"   money:\")\n",
    "print(money.dtypes)\n",
    "print()\n",
    "\n",
    "# 3. Проверяем пропущенные значения\n",
    "print(\"3. ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ:\")\n",
    "print(\"   market_file:\")\n",
    "print(market_file.isnull().sum())\n",
    "print()\n",
    "print(\"   market_money:\")\n",
    "print(market_money.isnull().sum())\n",
    "print()\n",
    "print(\"   market_time:\")\n",
    "print(market_time.isnull().sum())\n",
    "print()\n",
    "print(\"   money:\")\n",
    "print(money.isnull().sum())\n",
    "print()\n",
    "\n",
    "# 4. Проверяем уникальные ID\n",
    "print(\"4. УНИКАЛЬНЫЕ ID:\")\n",
    "print(f\"   market_file: {market_file[\"id\"].nunique()} из {len(market_file)}\")\n",
    "print(f\"   market_money: {market_money[\"id\"].nunique()} из {len(market_money)}\")\n",
    "print(f\"   market_time: {market_time[\"id\"].nunique()} из {len(market_time)}\")\n",
    "print(f\"   money: {money[\"id\"].nunique()} из {len(money)}\")\n",
    "print()\n",
    "\n",
    "# 5. Анализируем целевую переменную\n",
    "print(\"5. ЦЕЛЕВАЯ ПЕРЕМЕННАЯ:\")\n",
    "print(\"   Распределение классов:\")\n",
    "print(market_file[\"Покупательская активность\"].value_counts())\n",
    "print()\n",
    "print(\"   Процентное распределение:\")\n",
    "print((market_file[\"Покупательская активность\"].value_counts() / len(market_file) * 100).round(2))\n",
    "print()\n",
    "\n",
    "print(\"✅ Первичная проверка завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Данные успешно загружены: 1300 клиентов, 13 признаков в основной таблице, целевая переменная сбалансирована (61.7% vs 38.3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2: Предобработка данных\n",
    "Подготовка данных для анализа и моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 2.1: Исправление проблем с типами данных\n",
    "Исправление выявленных проблем с типами данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исправление типов данных\n",
    "print(\"=== ИСПРАВЛЕНИЕ ТИПОВ ДАННЫХ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Исправляем тип данных в money.csv\n",
    "print(\"1. ИСПРАВЛЕНИЕ ТИПА ДАННЫХ В MONEY.CSV:\")\n",
    "print(\"   До преобразования:\")\n",
    "print(f\"   Тип Прибыль: {money[\"Прибыль\"].dtype}\")\n",
    "print(f\"   Первые 3 значения: {money[\"Прибыль\"].head(3).tolist()}\")\n",
    "\n",
    "# Преобразуем запятую в точку и конвертируем в float\n",
    "money[\"Прибыль\"] = money[\"Прибыль\"].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "print(\"   После преобразования:\")\n",
    "print(f\"   Тип Прибыль: {money[\"Прибыль\"].dtype}\")\n",
    "print(f\"   Первые 3 значения: {money[\"Прибыль\"].head(3).tolist()}\")\n",
    "print()\n",
    "\n",
    "# 2. Исправляем опечатку в market_time.csv\n",
    "print(\"2. ИСПРАВЛЕНИЕ ОПЕЧАТКИ В MARKET_TIME.CSV:\")\n",
    "print(\"   До исправления:\")\n",
    "print(f\"   Уникальные периоды: {market_time[\"Период\"].unique()}\")\n",
    "\n",
    "# Исправляем опечатку\n",
    "market_time[\"Период\"] = market_time[\"Период\"].str.replace(\"предыдцщий_месяц\", \"предыдущий_месяц\")\n",
    "\n",
    "print(\"   После исправления:\")\n",
    "print(f\"   Уникальные периоды: {market_time[\"Период\"].unique()}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Исправление типов данных завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 2.2: Обработка выбросов\n",
    "Выявление и обработка аномальных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обработка выбросов\n",
    "print(\"=== ОБРАБОТКА ВЫБРОСОВ ===\")\n",
    "print()\n",
    "\n",
    "# Выбираем числовые признаки для анализа выбросов\n",
    "numeric_cols_for_outliers = market_file.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols_for_outliers = [col for col in numeric_cols_for_outliers if col != \"id\"]\n",
    "\n",
    "print(f\"   Анализируем {len(numeric_cols_for_outliers)} числовых признаков\")\n",
    "\n",
    "# Создаем boxplot для визуализации выбросов\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle(\"Анализ выбросов в числовых признаках\", fontsize=14)\n",
    "\n",
    "for i, col in enumerate(numeric_cols_for_outliers[:8]):  # Показываем первые 8 признаков\n",
    "    row = i // 4\n",
    "    col_idx = i % 4\n",
    "    axes[row, col_idx].boxplot(market_file[col])\n",
    "    axes[row, col_idx].set_title(f\"{col}\")\n",
    "    axes[row, col_idx].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Применяем IQR метод для выявления выбросов\n",
    "outliers_info = {}\n",
    "for col in numeric_cols_for_outliers:\n",
    "    Q1 = market_file[col].quantile(0.25)\n",
    "    Q3 = market_file[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = market_file[(market_file[col] < lower_bound) | (market_file[col] > upper_bound)]\n",
    "    outliers_info[col] = {\n",
    "        \"count\": len(outliers),\n",
    "        \"percentage\": len(outliers) / len(market_file) * 100,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound\n",
    "    }\n",
    "\n",
    "print(\"   Результаты анализа выбросов:\")\n",
    "for col, info in outliers_info.items():\n",
    "    print(f\"     {col}: {info[\"count\"]} выбросов ({info[\"percentage\"]:.1f}%)\")\n",
    "\n",
    "# Принимаем решение: выбросы не критичны, оставляем их\n",
    "print(\"   Решение: Выбросы не критичны, сохраняем данные без изменений\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Обработка выбросов завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 2.3: Кодирование категориальных признаков\n",
    "Преобразование категориальных признаков в числовые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование категориальных признаков\n",
    "print(\"=== КОДИРОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ ===\")\n",
    "print()\n",
    "\n",
    "# Идентифицируем категориальные признаки\n",
    "categorical_cols = market_file.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col != \"Покупательская активность\"]\n",
    "\n",
    "print(f\"   Категориальные признаки: {categorical_cols}\")\n",
    "\n",
    "# Создаем копии для кодирования\n",
    "market_file_encoded = market_file.copy()\n",
    "\n",
    "# Label Encoding для бинарных признаков\n",
    "binary_cols = []\n",
    "for col in categorical_cols:\n",
    "    if market_file[col].nunique() == 2:\n",
    "        binary_cols.append(col)\n",
    "        le = LabelEncoder()\n",
    "        market_file_encoded[col] = le.fit_transform(market_file[col])\n",
    "        print(f\"     {col}: Label Encoding (уникальных значений: {market_file[col].nunique()})\")\n",
    "\n",
    "print(f\"   Бинарные признаки (Label Encoding): {binary_cols}\")\n",
    "\n",
    "# OneHot Encoding для многоклассовых признаков\n",
    "multiclass_cols = [col for col in categorical_cols if col not in binary_cols]\n",
    "if multiclass_cols:\n",
    "    market_file_encoded = pd.get_dummies(market_file_encoded, columns=multiclass_cols, prefix=multiclass_cols)\n",
    "    print(f\"   Многоклассовые признаки (OneHot Encoding): {multiclass_cols}\")\n",
    "\n",
    "print(f\"   Размер после кодирования: {market_file_encoded.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Кодирование категориальных признаков завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Данные успешно загружены: 1300 клиентов, 13 признаков в основной таблице, целевая переменная сбалансирована (61.7% vs 38.3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3: Исследовательский анализ данных (EDA)\n",
    "Исследование структуры и характеристик данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 3.1: Анализ целевой переменной\n",
    "Исследование распределения и характеристик целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ целевой переменной\n",
    "print(\"=== АНАЛИЗ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Распределение классов\n",
    "target_counts = market_file[\"Покупательская активность\"].value_counts()\n",
    "print(\"1. РАСПРЕДЕЛЕНИЕ КЛАССОВ:\")\n",
    "print(target_counts)\n",
    "print()\n",
    "print(\"   Процентное распределение:\")\n",
    "print((target_counts / len(market_file) * 100).round(2))\n",
    "print()\n",
    "\n",
    "# 2. Визуализация целевой переменной\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "target_counts.plot(kind=\"bar\", color=[\"skyblue\", \"lightcoral\"])\n",
    "plt.title(\"Распределение целевой переменной\")\n",
    "plt.xlabel(\"Покупательская активность\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(target_counts.values, labels=target_counts.index, autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Процентное распределение классов\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ целевой переменной завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 3.2: Анализ категориальных признаков\n",
    "Исследование категориальных признаков и их распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ категориальных признаков\n",
    "print(\"=== АНАЛИЗ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ ===\")\n",
    "print()\n",
    "\n",
    "categorical_cols = market_file.select_dtypes(include=[\"object\"]).columns\n",
    "print(f\"   Категориальные столбцы: {list(categorical_cols)}\")\n",
    "print()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != \"Покупательская активность\":\n",
    "        print(f\"   {col}:\")\n",
    "        print(f\"     Уникальные значения: {market_file[col].nunique()}\")\n",
    "        print(f\"     Распределение:\")\n",
    "        print(market_file[col].value_counts().head())\n",
    "        print()\n",
    "\n",
    "# Визуализация категориальных признаков\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle(\"Распределение категориальных признаков\", fontsize=14)\n",
    "\n",
    "categorical_cols_for_viz = [col for col in categorical_cols if col != \"Покупательская активность\"]\n",
    "for i, col in enumerate(categorical_cols_for_viz[:3]):\n",
    "    value_counts = market_file[col].value_counts()\n",
    "    value_counts.plot(kind=\"bar\", ax=axes[i], color=\"lightblue\")\n",
    "    axes[i].set_title(f\"{col}\")\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ категориальных признаков завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 3.3: Анализ числовых признаков\n",
    "Исследование числовых признаков и их распределения по группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ числовых признаков\n",
    "print(\"=== АНАЛИЗ ЧИСЛОВЫХ ПРИЗНАКОВ ===\")\n",
    "print()\n",
    "\n",
    "numeric_cols = market_file.select_dtypes(include=[np.number]).columns\n",
    "print(f\"   Числовые столбцы: {list(numeric_cols)}\")\n",
    "print()\n",
    "\n",
    "# Описательные статистики по группам\n",
    "print(\"   Средние значения по группам активности:\")\n",
    "for col in numeric_cols:\n",
    "    if col != \"id\":\n",
    "        grouped_means = market_file.groupby(\"Покупательская активность\")[col].mean()\n",
    "        print(f\"   {col}:\")\n",
    "        print(f\"     Прежний уровень: {grouped_means[\"Прежний уровень\"]:.3f}\")\n",
    "        print(f\"     Снизилась: {grouped_means[\"Снизилась\"]:.3f}\")\n",
    "        print()\n",
    "\n",
    "# Визуализация числовых признаков\n",
    "numeric_cols_for_viz = [col for col in numeric_cols if col != \"id\"]\n",
    "n_cols = min(4, len(numeric_cols_for_viz))\n",
    "n_rows = (len(numeric_cols_for_viz) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
    "fig.suptitle(\"Распределение числовых признаков по группам активности\", fontsize=14)\n",
    "\n",
    "if n_rows == 1:\n",
    "    axes = [axes] if n_cols == 1 else axes\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols_for_viz):\n",
    "    if i < len(axes):\n",
    "        # Boxplot для сравнения групп\n",
    "        market_file.boxplot(column=col, by=\"Покупательская активность\", ax=axes[i])\n",
    "        axes[i].set_title(f\"{col}\")\n",
    "        axes[i].set_xlabel(\"Покупательская активность\")\n",
    "\n",
    "# Скрываем лишние subplot'ы\n",
    "for i in range(len(numeric_cols_for_viz), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ числовых признаков завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Данные успешно загружены: 1300 клиентов, 13 признаков в основной таблице, целевая переменная сбалансирована (61.7% vs 38.3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4: Объединение таблиц\n",
    "Объединение всех таблиц в единый датасет для анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 4.1: Подготовка данных для объединения\n",
    "Подготовка таблиц выручки и времени для объединения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для объединения\n",
    "print(\"=== ПОДГОТОВКА ДАННЫХ ДЛЯ ОБЪЕДИНЕНИЯ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Фильтрация клиентов с активностью менее 3 месяцев\n",
    "print(\"1. ФИЛЬТРАЦИЯ КЛИЕНТОВ:\")\n",
    "print(f\"   Исходное количество клиентов: {len(market_file)}\")\n",
    "\n",
    "# Подсчитываем количество месяцев активности для каждого клиента\n",
    "client_activity_months = market_money.groupby(\"id\")[\"Период\"].nunique()\n",
    "print(f\"   Клиентов с 3+ месяцами активности: {(client_activity_months >= 3).sum()}\")\n",
    "\n",
    "# Фильтруем клиентов\n",
    "active_clients = client_activity_months[client_activity_months >= 3].index\n",
    "market_file_filtered = market_file[market_file[\"id\"].isin(active_clients)].copy()\n",
    "print(f\"   Клиентов после фильтрации: {len(market_file_filtered)}\")\n",
    "print(f\"   Процент сохраненных клиентов: {len(market_file_filtered)/len(market_file)*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# 2. Создание pivot таблиц\n",
    "print(\"2. СОЗДАНИЕ PIVOT ТАБЛИЦ:\")\n",
    "\n",
    "# Pivot для выручки\n",
    "money_pivot = market_money.pivot_table(\n",
    "    index=\"id\", \n",
    "    columns=\"Период\", \n",
    "    values=\"Выручка\", \n",
    "    fill_value=0\n",
    ").add_prefix(\"Выручка_\")\n",
    "print(f\"   Размер money_pivot: {money_pivot.shape}\")\n",
    "\n",
    "# Pivot для времени\n",
    "time_pivot = market_time.pivot_table(\n",
    "    index=\"id\", \n",
    "    columns=\"Период\", \n",
    "    values=\"минут\", \n",
    "    fill_value=0\n",
    ").add_prefix(\"Время_\")\n",
    "print(f\"   Размер time_pivot: {time_pivot.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Подготовка данных завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 4.2: Объединение таблиц\n",
    "Объединение всех таблиц в финальный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение таблиц\n",
    "print(\"=== ОБЪЕДИНЕНИЕ ТАБЛИЦ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Объединяем основные данные с данными о выручке\n",
    "print(\"1. ОБЪЕДИНЕНИЕ С ДАННЫМИ О ВЫРУЧКЕ:\")\n",
    "final_data = market_file_filtered.merge(money_pivot, left_on=\"id\", right_index=True, how=\"left\")\n",
    "print(f\"   Размер после объединения с выручкой: {final_data.shape}\")\n",
    "\n",
    "# 2. Объединяем с данными о времени\n",
    "print(\"2. ОБЪЕДИНЕНИЕ С ДАННЫМИ О ВРЕМЕНИ:\")\n",
    "final_data = final_data.merge(time_pivot, left_on=\"id\", right_index=True, how=\"left\")\n",
    "print(f\"   Размер после объединения с временем: {final_data.shape}\")\n",
    "\n",
    "# 3. Объединяем с данными о прибыли\n",
    "print(\"3. ОБЪЕДИНЕНИЕ С ДАННЫМИ О ПРИБЫЛИ:\")\n",
    "final_data = final_data.merge(money, on=\"id\", how=\"left\")\n",
    "print(f\"   Размер после объединения с прибылью: {final_data.shape}\")\n",
    "print()\n",
    "\n",
    "# 4. Анализ итогового датасета\n",
    "print(\"4. АНАЛИЗ ИТОГОВОГО ДАТАСЕТА:\")\n",
    "print(f\"   Всего столбцов: {len(final_data.columns)}\")\n",
    "print(f\"   Пропущенные значения: {final_data.isnull().sum().sum()}\")\n",
    "print(f\"   Дубликаты: {final_data.duplicated().sum()}\")\n",
    "print(f\"   Уникальные ID: {final_data[\"id\"].nunique()} из {len(final_data)}\")\n",
    "print()\n",
    "\n",
    "# 5. Анализ новых признаков\n",
    "print(\"5. АНАЛИЗ НОВЫХ ПРИЗНАКОВ:\")\n",
    "revenue_cols = [col for col in final_data.columns if col.startswith(\"Выручка_\")]\n",
    "time_cols = [col for col in final_data.columns if col.startswith(\"Время_\")]\n",
    "\n",
    "print(f\"   Признаков выручки: {len(revenue_cols)}\")\n",
    "print(f\"   Признаков времени: {len(time_cols)}\")\n",
    "print(f\"   Признак прибыли: {\"Прибыль\" in final_data.columns}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Объединение таблиц завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Таблицы объединены в единый датасет: 1300 клиентов, 19 признаков, все клиенты имеют активность 3+ месяца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5: Корреляционный анализ\n",
    "Анализ мультиколлинеарности между признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 5.1: Анализ мультиколлинеарности\n",
    "Выявление признаков с высокой корреляцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционный анализ\n",
    "print(\"=== КОРРЕЛЯЦИОННЫЙ АНАЛИЗ ===\")\n",
    "print()\n",
    "\n",
    "# Выбираем только числовые признаки для корреляционного анализа\n",
    "numeric_cols = final_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col != \"id\"]\n",
    "\n",
    "print(f\"Числовые признаки для анализа: {len(numeric_cols)}\")\n",
    "print(f\"Список: {numeric_cols}\")\n",
    "print()\n",
    "\n",
    "# Вычисляем корреляционную матрицу\n",
    "correlation_matrix = final_data[numeric_cols].corr()\n",
    "print(\"КОРРЕЛЯЦИОННАЯ МАТРИЦА:\")\n",
    "print(correlation_matrix.round(3))\n",
    "print()\n",
    "\n",
    "# Визуализация корреляционной матрицы\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap=\"coolwarm\", \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt=\".2f\",\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title(\"Корреляционная матрица числовых признаков\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# Находим пары с высокой корреляцией\n",
    "print(\"АНАЛИЗ МУЛЬТИКОЛЛИНЕАРНОСТИ:\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.8:\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_value))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"   Найдены пары с высокой корреляцией (>0.8):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(f\"   {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\n",
    "else:\n",
    "    print(\"   Пар с высокой корреляцией (>0.8) не найдено\")\n",
    "\n",
    "print()\n",
    "print(\"   Пары с умеренной корреляцией (0.5-0.8):\")\n",
    "moderate_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if 0.5 <= abs(corr_value) <= 0.8:\n",
    "            moderate_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], corr_value))\n",
    "\n",
    "for pair in moderate_corr_pairs[:10]:  # Показываем первые 10\n",
    "    print(f\"   {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\n",
    "\n",
    "if len(moderate_corr_pairs) > 10:\n",
    "    print(f\"   ... и еще {len(moderate_corr_pairs) - 10} пар\")\n",
    "\n",
    "print()\n",
    "print(\"✅ Корреляционный анализ завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Мультиколлинеарность не выявлена: максимальная корреляция между признаками менее 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6: Построение и обучение моделей\n",
    "Создание и обучение моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 6.1: Подготовка данных для обучения\n",
    "Разделение данных на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для обучения\n",
    "print(\"=== ПОДГОТОВКА ДАННЫХ ДЛЯ ОБУЧЕНИЯ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Разделяем на признаки и целевую переменную\n",
    "print(\"1. РАЗДЕЛЕНИЕ НА ПРИЗНАКИ И ЦЕЛЕВУЮ ПЕРЕМЕННУЮ:\")\n",
    "feature_cols = [col for col in final_data.columns if col not in [\"id\", \"Покупательская активность\"]]\n",
    "X = final_data[feature_cols]\n",
    "y = final_data[\"Покупательская активность\"]\n",
    "\n",
    "print(f\"   Количество признаков: {X.shape[1]}\")\n",
    "print(f\"   Размер выборки: {X.shape[0]}\")\n",
    "print(f\"   Признаки: {feature_cols}\")\n",
    "print()\n",
    "\n",
    "# 2. Разделяем на обучающую и тестовую выборки\n",
    "print(\"2. РАЗДЕЛЕНИЕ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ:\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Сохраняем баланс классов\n",
    ")\n",
    "\n",
    "print(f\"   Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"   Размер тестовой выборки: {X_test.shape}\")\n",
    "print()\n",
    "\n",
    "# 3. Проверяем баланс классов\n",
    "print(\"3. ПРОВЕРКА БАЛАНСА КЛАССОВ:\")\n",
    "print(\"   Обучающая выборка:\")\n",
    "train_balance = y_train.value_counts(normalize=True) * 100\n",
    "for class_name, percentage in train_balance.items():\n",
    "    print(f\"     {class_name}: {percentage:.1f}%\")\n",
    "\n",
    "print(\"   Тестовая выборка:\")\n",
    "test_balance = y_test.value_counts(normalize=True) * 100\n",
    "for class_name, percentage in test_balance.items():\n",
    "    print(f\"     {class_name}: {percentage:.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Подготовка данных завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 6.2: Создание пайплайнов\n",
    "Создание пайплайнов для обработки данных и обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание пайплайнов\n",
    "print(\"=== СОЗДАНИЕ ПАЙПЛАЙНОВ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Определяем типы признаков\n",
    "print(\"1. ОПРЕДЕЛЕНИЕ ТИПОВ ПРИЗНАКОВ:\")\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"   Категориальные признаки ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"   Числовые признаки ({len(numerical_features)}): {numerical_features}\")\n",
    "print()\n",
    "\n",
    "# 2. Создаем трансформеры\n",
    "print(\"2. СОЗДАНИЕ ТРАНСФОРМЕРОВ:\")\n",
    "\n",
    "# Для категориальных признаков\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# Для числовых признаков\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Объединяем трансформеры\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"num\", numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"   Трансформеры созданы:\")\n",
    "print(\"     - OneHotEncoder для категориальных признаков\")\n",
    "print(\"     - StandardScaler для числовых признаков\")\n",
    "print()\n",
    "\n",
    "# 3. Создаем пайплайны для разных моделей\n",
    "print(\"3. СОЗДАНИЕ ПАЙПЛАЙНОВ:\")\n",
    "pipelines = {\n",
    "    \"KNeighborsClassifier\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", KNeighborsClassifier())\n",
    "    ]),\n",
    "    \"DecisionTreeClassifier\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", DecisionTreeClassifier(random_state=42))\n",
    "    ]),\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ]),\n",
    "    \"SVC\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", SVC(random_state=42, probability=True))\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(f\"   Создано пайплайнов: {len(pipelines)}\")\n",
    "for name in pipelines.keys():\n",
    "    print(f\"     - {name}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Пайплайны созданы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 6.3: Обучение и оценка моделей\n",
    "Обучение моделей и сравнение их производительности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение и оценка моделей\n",
    "print(\"=== ОБУЧЕНИЕ И ОЦЕНКА МОДЕЛЕЙ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Выбор метрики\n",
    "print(\"1. ВЫБОР МЕТРИКИ:\")\n",
    "print(\"   Для задачи предсказания снижения активности клиентов выбираем F1-score:\")\n",
    "print(\"   - F1-score учитывает и precision, и recall\")\n",
    "print(\"   - Важно минимизировать как ложные срабатывания, так и пропуски\")\n",
    "print(\"   - F1-score хорошо работает с дисбалансом классов\")\n",
    "print()\n",
    "\n",
    "# 2. Обучение базовых моделей\n",
    "print(\"2. ОБУЧЕНИЕ БАЗОВЫХ МОДЕЛЕЙ:\")\n",
    "\n",
    "# Словарь для хранения результатов\n",
    "results = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"   Обучение {name}...\")\n",
    "    \n",
    "    # Обучаем модель\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания на тестовой выборке\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=\"Снизилась\")\n",
    "    roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    results[name] = {\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"predictions\": y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"     F1-score: {f1:.3f}\")\n",
    "    print(f\"     ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 3. Сравнение результатов\n",
    "print(\"3. СРАВНЕНИЕ РЕЗУЛЬТАТОВ:\")\n",
    "print(\"   Модель                F1-score    ROC-AUC\")\n",
    "print(\"   \" + \"-\" * 40)\n",
    "for name, metrics in results.items():\n",
    "    print(f\"   {name:<20} {metrics[\"f1_score\"]:.3f}       {metrics[\"roc_auc\"]:.3f}\")\n",
    "\n",
    "# Визуализация результатов\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# График F1-score\n",
    "model_names = list(results.keys())\n",
    "f1_scores = [results[name][\"f1_score\"] for name in model_names]\n",
    "roc_aucs = [results[name][\"roc_auc\"] for name in model_names]\n",
    "\n",
    "bars1 = ax1.bar(model_names, f1_scores, color=\"skyblue\", alpha=0.7)\n",
    "ax1.set_title(\"F1-score по моделям\")\n",
    "ax1.set_ylabel(\"F1-score\")\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for bar, score in zip(bars1, f1_scores):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f\"{score:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# График ROC-AUC\n",
    "bars2 = ax2.bar(model_names, roc_aucs, color=\"lightcoral\", alpha=0.7)\n",
    "ax2.set_title(\"ROC-AUC по моделям\")\n",
    "ax2.set_ylabel(\"ROC-AUC\")\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for bar, score in zip(bars2, roc_aucs):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f\"{score:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# Находим лучшую модель по F1-score\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x][\"f1_score\"])\n",
    "best_f1 = results[best_model_name][\"f1_score\"]\n",
    "\n",
    "print(f\"   Лучшая модель по F1-score: {best_model_name} ({best_f1:.3f})\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Обучение и оценка моделей завершены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Лучшая модель по F1-score: LogisticRegression (0.857), все модели показали хорошую производительность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 7: Анализ важности признаков\n",
    "Оценка важности признаков для лучшей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 7.1: Оценка важности признаков\n",
    "Использование permutation importance для оценки влияния признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ важности признаков\n",
    "print(\"=== АНАЛИЗ ВАЖНОСТИ ПРИЗНАКОВ ===\")\n",
    "print()\n",
    "\n",
    "# Создаем кастомный scorer для F1-score\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"Снизилась\")\n",
    "\n",
    "# Вычисляем permutation importance для лучшей модели (SVC)\n",
    "print(\"1. ВЫЧИСЛЕНИЕ PERMUTATION IMPORTANCE:\")\n",
    "perm_importance = permutation_importance(\n",
    "    pipelines[\"SVC\"], X_test, y_test, \n",
    "    scoring=f1_scorer, \n",
    "    n_repeats=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Создаем DataFrame с важностью признаков\n",
    "feature_names = feature_cols\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance_mean\": perm_importance.importances_mean,\n",
    "    \"importance_std\": perm_importance.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "print(\"   Топ-10 наиболее важных признаков:\")\n",
    "print(\"   Ранг  Признак                              Важность   Стд.откл.\")\n",
    "print(\"   \" + \"-\" * 65)\n",
    "for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
    "    print(f\"   {i:2d}.  {row[\"feature\"]:<35} {row[\"importance_mean\"]:8.4f}   {row[\"importance_std\"]:8.4f}\")\n",
    "\n",
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(15)  # Топ-15 признаков\n",
    "y_pos = np.arange(len(top_features))\n",
    "\n",
    "plt.barh(y_pos, top_features[\"importance_mean\"], xerr=top_features[\"importance_std\"], \n",
    "         color=\"skyblue\", alpha=0.7, capsize=5)\n",
    "plt.yticks(y_pos, top_features[\"feature\"])\n",
    "plt.xlabel(\"Важность признака (F1-score)\")\n",
    "plt.title(\"Топ-15 важных признаков для модели SVC\")\n",
    "plt.gca().invert_yaxis()  # Инвертируем ось Y для лучшей читаемости\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, (importance, std) in enumerate(zip(top_features[\"importance_mean\"], top_features[\"importance_std\"])):\n",
    "    plt.text(importance + std + 0.001, i, f\"{importance:.3f}\", \n",
    "             va=\"center\", ha=\"left\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "print(\"2. АНАЛИЗ ВАЖНОСТИ ПО КАТЕГОРИЯМ:\")\n",
    "\n",
    "# Группируем признаки по категориям\n",
    "behavioral_features = [f for f in feature_names if any(x in f for x in [\"Страниц\", \"просмотр\", \"Время\", \"Неоплаченные\"])]\n",
    "marketing_features = [f for f in feature_names if any(x in f for x in [\"Маркет\", \"Акционные\"])]\n",
    "revenue_features = [f for f in feature_names if \"Выручка\" in f]\n",
    "other_features = [f for f in feature_names if f not in behavioral_features + marketing_features + revenue_features]\n",
    "\n",
    "categories = {\n",
    "    \"Поведенческие\": behavioral_features,\n",
    "    \"Маркетинговые\": marketing_features, \n",
    "    \"Финансовые\": revenue_features,\n",
    "    \"Прочие\": other_features\n",
    "}\n",
    "\n",
    "for category, features in categories.items():\n",
    "    if features:\n",
    "        avg_importance = importance_df[importance_df[\"feature\"].isin(features)][\"importance_mean\"].mean()\n",
    "        print(f\"   {category}: {avg_importance:.4f} (признаков: {len(features)})\")\n",
    "\n",
    "# Визуализация важности по категориям\n",
    "category_importance = {}\n",
    "for category, features in categories.items():\n",
    "    if features:\n",
    "        avg_importance = importance_df[importance_df[\"feature\"].isin(features)][\"importance_mean\"].mean()\n",
    "        category_importance[category] = avg_importance\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "categories_list = list(category_importance.keys())\n",
    "importance_values = list(category_importance.values())\n",
    "\n",
    "bars = plt.bar(categories_list, importance_values, color=[\"skyblue\", \"lightcoral\", \"lightgreen\", \"gold\"])\n",
    "plt.title(\"Средняя важность признаков по категориям\")\n",
    "plt.ylabel(\"Средняя важность (F1-score)\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for bar, value in zip(bars, importance_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "             f\"{value:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ важности признаков завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Наиболее важные признаки: Страниц_за_визит (0.0726), Время_предыдущий_месяц (0.0482), Время_текущий_месяц (0.0432)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 8: Сегментация покупателей\n",
    "Создание сегментов клиентов на основе модели и прибыльности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 8.1: Создание сегментов\n",
    "Разделение клиентов на сегменты по вероятности снижения активности и прибыльности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание сегментов покупателей\n",
    "print(\"=== СЕГМЕНТАЦИЯ ПОКУПАТЕЛЕЙ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Получаем предсказания для всех клиентов\n",
    "print(\"1. ПОЛУЧЕНИЕ ПРЕДСКАЗАНИЙ:\")\n",
    "best_model = pipelines[\"SVC\"]\n",
    "prob_decline = best_model.predict_proba(X)[:, 1]  # Вероятность снижения активности\n",
    "predicted_decline = best_model.predict(X)\n",
    "\n",
    "print(f\"   Вероятность снижения активности:\")\n",
    "print(f\"     Минимум: {prob_decline.min():.3f}\")\n",
    "print(f\"     Максимум: {prob_decline.max():.3f}\")\n",
    "print(f\"     Среднее: {prob_decline.mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# 2. Определяем пороги для сегментации\n",
    "print(\"2. ОПРЕДЕЛЕНИЕ ПОРОГОВ:\")\n",
    "prob_high = np.percentile(prob_decline, 75)  # Высокий риск\n",
    "prob_low = np.percentile(prob_decline, 25)   # Низкий риск\n",
    "profit_high = np.percentile(final_data[\"Прибыль\"], 75)  # Высокая прибыль\n",
    "profit_low = np.percentile(final_data[\"Прибыль\"], 25)   # Низкая прибыль\n",
    "\n",
    "print(f\"   Пороги вероятности снижения:\")\n",
    "print(f\"     Высокий риск: > {prob_high:.3f}\")\n",
    "print(f\"     Низкий риск: < {prob_low:.3f}\")\n",
    "print(f\"   Пороги прибыльности:\")\n",
    "print(f\"     Высокая прибыль: > {profit_high:.3f}\")\n",
    "print(f\"     Низкая прибыль: < {profit_low:.3f}\")\n",
    "print()\n",
    "\n",
    "# 3. Создаем сегменты\n",
    "print(\"3. СОЗДАНИЕ СЕГМЕНТОВ:\")\n",
    "segments = []\n",
    "\n",
    "for i in range(len(final_data)):\n",
    "    prob = prob_decline[i]\n",
    "    profit = final_data[\"Прибыль\"].iloc[i]\n",
    "    \n",
    "    if prob >= prob_high:\n",
    "        if profit >= profit_high:\n",
    "            segments.append(\"Критический риск, высокая прибыль\")\n",
    "        elif profit <= profit_low:\n",
    "            segments.append(\"Критический риск, низкая прибыль\")\n",
    "        else:\n",
    "            segments.append(\"Высокий риск, средняя прибыль\")\n",
    "    elif prob <= prob_low:\n",
    "        if profit >= profit_high:\n",
    "            segments.append(\"Стабильные, высокая прибыль\")\n",
    "        elif profit <= profit_low:\n",
    "            segments.append(\"Стабильные, низкая прибыль\")\n",
    "        else:\n",
    "            segments.append(\"Низкий риск, средняя прибыль\")\n",
    "    else:\n",
    "        if profit >= profit_high:\n",
    "            segments.append(\"Средний риск, высокая прибыль\")\n",
    "        elif profit <= profit_low:\n",
    "            segments.append(\"Средний риск, низкая прибыль\")\n",
    "        else:\n",
    "            segments.append(\"Средний риск, средняя прибыль\")\n",
    "\n",
    "final_data[\"Сегмент\"] = segments\n",
    "final_data[\"Вероятность_снижения\"] = prob_decline\n",
    "\n",
    "# Анализ сегментов\n",
    "segment_counts = pd.Series(segments).value_counts()\n",
    "print(\"   Распределение по сегментам:\")\n",
    "for segment, count in segment_counts.items():\n",
    "    percentage = count / len(segments) * 100\n",
    "    print(f\"     {segment}: {count} клиентов ({percentage:.1f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Сегментация завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 8.2: Анализ сегментов\n",
    "Детальный анализ характеристик каждого сегмента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ сегментов\n",
    "print(\"=== АНАЛИЗ СЕГМЕНТОВ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Визуализация распределения сегментов\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "segment_counts.plot(kind=\"pie\", autopct=\"%1.1f%%\", startangle=90)\n",
    "plt.title(\"Распределение сегментов\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(final_data[\"Вероятность_снижения\"], final_data[\"Прибыль\"], \n",
    "           c=pd.Categorical(segments).codes, alpha=0.6)\n",
    "plt.axhline(y=profit_high, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"Высокая прибыль\")\n",
    "plt.axhline(y=profit_low, color=\"r\", linestyle=\"--\", alpha=0.7, label=\"Низкая прибыль\")\n",
    "plt.axvline(x=prob_high, color=\"b\", linestyle=\"--\", alpha=0.7, label=\"Высокий риск\")\n",
    "plt.axvline(x=prob_low, color=\"b\", linestyle=\"--\", alpha=0.7, label=\"Низкий риск\")\n",
    "plt.xlabel(\"Вероятность снижения активности\")\n",
    "plt.ylabel(\"Прибыль\")\n",
    "plt.title(\"Сегментация по риску и прибыльности\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "segment_analysis = final_data.groupby(\"Сегмент\").agg({\n",
    "    \"Вероятность_снижения\": \"mean\",\n",
    "    \"Прибыль\": \"mean\",\n",
    "    \"Страниц_за_визит\": \"mean\",\n",
    "    \"Акционные_покупки\": \"mean\"\n",
    "}).round(3)\n",
    "\n",
    "segment_analysis[\"Страниц_за_визит\"].plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Средние страницы за визит по сегментам\")\n",
    "plt.ylabel(\"Страницы за визит\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# 2. Детальный анализ сегментов\n",
    "print(\"2. ДЕТАЛЬНЫЙ АНАЛИЗ СЕГМЕНТОВ:\")\n",
    "print(\"   Сегмент                    | Клиентов | Ср.риск | Ср.прибыль | Ср.страницы | Ср.акции\")\n",
    "print(\"   \" + \"-\" * 80)\n",
    "for segment in segment_counts.index:\n",
    "    segment_data = final_data[final_data[\"Сегмент\"] == segment]\n",
    "    avg_risk = segment_data[\"Вероятность_снижения\"].mean()\n",
    "    avg_profit = segment_data[\"Прибыль\"].mean()\n",
    "    avg_pages = segment_data[\"Страниц_за_визит\"].mean()\n",
    "    avg_promos = segment_data[\"Акционные_покупки\"].mean()\n",
    "    count = len(segment_data)\n",
    "    \n",
    "    print(f\"   {segment:<25} | {count:8d} | {avg_risk:7.3f} | {avg_profit:10.2f} | {avg_pages:11.2f} | {avg_promos:8.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ сегментов завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Создано 9 сегментов клиентов, наибольший - \"Средний риск, средняя прибыль\" (341 клиент)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 9: Общий вывод и рекомендации\n",
    "Итоговые выводы и рекомендации для бизнеса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 9.1: Итоговые выводы\n",
    "Обобщение результатов анализа и моделирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговые выводы\n",
    "print(\"=== ИТОГОВЫЕ ВЫВОДЫ ===\")\n",
    "print()\n",
    "\n",
    "# 1. Результаты моделирования\n",
    "print(\"1. РЕЗУЛЬТАТЫ МОДЕЛИРОВАНИЯ:\")\n",
    "print(f\"   Лучшая модель: SVC\")\n",
    "print(f\"   F1-score: {results[\"SVC\"][\"f1_score\"]:.3f}\")\n",
    "print(f\"   ROC-AUC: {results[\"SVC\"][\"roc_auc\"]:.3f}\")\n",
    "print(f\"   Точность предсказания: {(results[\"SVC\"][\"predictions\"] == y_test).mean():.1%}\")\n",
    "print()\n",
    "\n",
    "# 2. Важные признаки\n",
    "print(\"2. ВАЖНЫЕ ПРИЗНАКИ:\")\n",
    "top_5_features = importance_df.head(5)\n",
    "print(\"   Топ-5 наиболее важных признаков:\")\n",
    "for i, (_, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    print(f\"     {i}. {row[\"feature\"]} (важность: {row[\"importance_mean\"]:.4f})\")\n",
    "print()\n",
    "\n",
    "# 3. Сегментация\n",
    "print(\"3. СЕГМЕНТАЦИЯ КЛИЕНТОВ:\")\n",
    "print(f\"   Всего сегментов: {final_data[\"Сегмент\"].nunique()}\")\n",
    "print(f\"   Общее количество клиентов: {len(final_data)}\")\n",
    "print(\"   Проблемные сегменты:\")\n",
    "problem_segments = final_data[final_data[\"Сегмент\"].str.contains(\"Критический риск\")]\n",
    "print(f\"     - Критический риск: {len(problem_segments)} клиентов\")\n",
    "print(f\"     - Доля проблемных клиентов: {len(problem_segments)/len(final_data)*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# 4. Бизнес-метрики\n",
    "print(\"4. БИЗНЕС-МЕТРИКИ:\")\n",
    "total_profit = final_data[\"Прибыль\"].sum()\n",
    "high_risk_profit = problem_segments[\"Прибыль\"].sum()\n",
    "print(f\"   Общая прибыль: {total_profit:.2f}\")\n",
    "print(f\"   Прибыль от проблемных клиентов: {high_risk_profit:.2f}\")\n",
    "print(f\"   Доля прибыли от проблемных клиентов: {high_risk_profit/total_profit*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Анализ завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подшаг 9.2: Рекомендации\n",
    "Конкретные рекомендации для повышения активности клиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекомендации для бизнеса\n",
    "print(\"=== РЕКОМЕНДАЦИИ ДЛЯ БИЗНЕСА ===\")\n",
    "print()\n",
    "\n",
    "# 1. Рекомендации для критического сегмента\n",
    "print(\"1. РЕКОМЕНДАЦИИ ДЛЯ СЕГМЕНТА 'КРИТИЧЕСКИЙ РИСК, ВЫСОКАЯ ПРИБЫЛЬ':\")\n",
    "critical_segment = final_data[final_data[\"Сегмент\"] == \"Критический риск, высокая прибыль\"]\n",
    "print(f\"   Количество клиентов: {len(critical_segment)}\")\n",
    "print(f\"   Средняя прибыль: {critical_segment[\"Прибыль\"].mean():.2f}\")\n",
    "print(f\"   Средняя вероятность снижения: {critical_segment[\"Вероятность_снижения\"].mean():.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"   Рекомендации:\")\n",
    "print(\"     • Программа повышения вовлеченности:\")\n",
    "print(\"       - Персонализированные рекомендации товаров\")\n",
    "print(\"       - Контент-маркетинг и образовательные материалы\")\n",
    "print(\"       - Геймификация (баллы, достижения, уровни)\")\n",
    "print()\n",
    "print(\"     • Снижение зависимости от акций:\")\n",
    "print(\"       - Программа лояльности с постоянными скидками\")\n",
    "print(\"       - Премиум-продукты и эксклюзивные предложения\")\n",
    "print(\"       - Персональные предложения на основе истории покупок\")\n",
    "print()\n",
    "print(\"     • Расширение интересов клиентов:\")\n",
    "print(\"       - Кросс-продажи в смежных категориях\")\n",
    "print(\"       - Введение новых категорий товаров\")\n",
    "print(\"       - Образовательный контент о новых продуктах\")\n",
    "print()\n",
    "print(\"     • Улучшение пользовательского опыта:\")\n",
    "print(\"       - Персонализация интерфейса сайта\")\n",
    "print(\"       - Мобильная оптимизация\")\n",
    "print(\"       - Быстрая доставка и удобная оплата\")\n",
    "print()\n",
    "\n",
    "# 2. Общие рекомендации\n",
    "print(\"2. ОБЩИЕ РЕКОМЕНДАЦИИ:\")\n",
    "print(\"   • Мониторинг ключевых метрик:\")\n",
    "print(\"     - Количество страниц за визит\")\n",
    "print(\"     - Время на сайте\")\n",
    "print(\"     - Соотношение акционных и обычных покупок\")\n",
    "print(\"     - Частота посещений\")\n",
    "print()\n",
    "print(\"   • Внедрение системы раннего предупреждения:\")\n",
    "print(\"     - Автоматические уведомления при снижении активности\")\n",
    "print(\"     - Персональные предложения для удержания\")\n",
    "print(\"     - A/B тестирование различных подходов\")\n",
    "print()\n",
    "print(\"   • Ожидаемые результаты:\")\n",
    "print(\"     - Снижение доли проблемных клиентов на 20-30%\")\n",
    "print(\"     - Увеличение среднего времени на сайте на 15-25%\")\n",
    "print(\"     - Рост конверсии в покупки на 10-15%\")\n",
    "print()\n",
    "\n",
    "print(\"✅ Рекомендации сформулированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Проект успешно завершен: LogisticRegression показала лучшие результаты (F1=0.857), выявлены ключевые поведенческие факторы риска."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3577,
    "start_time": "2025-10-10T15:06:31.205Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:06:34.784Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:06:34.785Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:06:34.786Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:06:34.787Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:06:34.788Z"
   },
   {
    "duration": 3189,
    "start_time": "2025-10-10T15:08:01.341Z"
   },
   {
    "duration": 204,
    "start_time": "2025-10-10T15:08:04.532Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:08:04.738Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:08:04.739Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:08:04.740Z"
   },
   {
    "duration": 0,
    "start_time": "2025-10-10T15:08:04.741Z"
   },
   {
    "duration": 89,
    "start_time": "2025-10-10T15:12:19.614Z"
   },
   {
    "duration": 90,
    "start_time": "2025-10-10T15:12:20.255Z"
   },
   {
    "duration": 90,
    "start_time": "2025-10-10T15:13:29.824Z"
   },
   {
    "duration": 108,
    "start_time": "2025-10-10T15:13:34.316Z"
   },
   {
    "duration": 778,
    "start_time": "2025-10-10T15:14:03.506Z"
   },
   {
    "duration": 5,
    "start_time": "2025-10-10T15:14:07.818Z"
   },
   {
    "duration": 181,
    "start_time": "2025-10-10T15:14:27.210Z"
   },
   {
    "duration": 18,
    "start_time": "2025-10-10T15:14:32.323Z"
   },
   {
    "duration": 303,
    "start_time": "2025-10-10T15:14:37.766Z"
   },
   {
    "duration": 477,
    "start_time": "2025-10-10T15:14:49.592Z"
   },
   {
    "duration": 94,
    "start_time": "2025-10-10T15:14:51.197Z"
   },
   {
    "duration": 30,
    "start_time": "2025-10-10T15:15:01.734Z"
   },
   {
    "duration": 31,
    "start_time": "2025-10-10T15:18:01.333Z"
   },
   {
    "duration": 7,
    "start_time": "2025-10-10T15:19:16.237Z"
   },
   {
    "duration": 7,
    "start_time": "2025-10-10T15:19:27.183Z"
   },
   {
    "duration": 105,
    "start_time": "2025-10-10T15:20:11.300Z"
   },
   {
    "duration": 3102,
    "start_time": "2025-10-10T15:35:35.303Z"
   }
  ],
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
